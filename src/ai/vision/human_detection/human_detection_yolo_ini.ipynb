{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a347f1bb",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55458056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Add utils to path\n",
    "sys.path.append('./utils')\n",
    "from data_utils import (\n",
    "    load_config, \n",
    "    visualize_annotations, \n",
    "    count_images_and_labels,\n",
    "    analyze_dataset_distribution,\n",
    "    plot_training_results\n",
    ")\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4626e827",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / 'data' / 'final_train'\n",
    "MODELS_DIR = PROJECT_ROOT / 'models'\n",
    "PRETRAINED_DIR = MODELS_DIR / 'pretrained'\n",
    "TRAINED_DIR = MODELS_DIR / 'trained/combinedV2'\n",
    "CONFIGS_DIR = PROJECT_ROOT / 'configs'\n",
    "RESULTS_DIR = PROJECT_ROOT / 'combined/results'\n",
    "PREDICTIONS_DIR = RESULTS_DIR / 'predictions'\n",
    "METRICS_DIR = RESULTS_DIR / 'metrics'\n",
    "\n",
    "for dir_path in [PRETRAINED_DIR, TRAINED_DIR, PREDICTIONS_DIR, METRICS_DIR]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Project directories initialized\")\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "print(f\"Data Directory: {DATA_DIR}\")\n",
    "print(f\"Models Directory: {MODELS_DIR}\")\n",
    "print(f\"Results Directory: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f52b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_config = load_config(CONFIGS_DIR / 'data_config.yaml')\n",
    "model_config = load_config(CONFIGS_DIR / 'model_config.yaml')\n",
    "inference_config = load_config(CONFIGS_DIR / 'inference_config.yaml')\n",
    "\n",
    "print(\"Configuration files loaded\")\n",
    "print(f\"\\n Dataset Config:\")\n",
    "print(f\"  - Classes: {data_config['names']}\")\n",
    "print(f\"  - Number of classes: {data_config['nc']}\")\n",
    "print(f\"  - Image size: {data_config['imgsz']}\")\n",
    "\n",
    "print(f\"\\n Model Config:\")\n",
    "print(f\"  - Model: {model_config['model_name']}\")\n",
    "print(f\"  - Epochs: {model_config['epochs']}\")\n",
    "print(f\"  - Batch size: {model_config['batch']}\")\n",
    "print(f\"  - Optimizer: {model_config['optimizer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e97b7e8",
   "metadata": {},
   "source": [
    "## 2. Data Exploration and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4fe9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exists = DATA_DIR.exists()\n",
    "print(f\"Dataset directory exists: {data_exists}\")\n",
    "\n",
    "if data_exists:\n",
    "    # Check dataset structure\n",
    "    required_dirs = [\n",
    "        DATA_DIR / 'images' / 'train',\n",
    "        DATA_DIR / 'images' / 'val',\n",
    "        DATA_DIR / 'labels' / 'train',\n",
    "        DATA_DIR / 'labels' / 'val'\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n Dataset Structure:\")\n",
    "    for dir_path in required_dirs:\n",
    "        exists = dir_path.exists()\n",
    "        status = \"\" if exists else \" MISSING\"\n",
    "        print(f\"{status} {dir_path.relative_to(PROJECT_ROOT)}\")\n",
    "else:\n",
    "    print(\"\\nDataset not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78000b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images and labels in each split\n",
    "if data_exists:\n",
    "    stats = count_images_and_labels(DATA_DIR)\n",
    "    \n",
    "    print(\"\\nDataset Statistics:\")\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    for split, counts in stats.items():\n",
    "        print(f\"{split.upper():8s} - Images: {counts['images']:5d}, Labels: {counts['labels']:5d}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    total_images = sum(s['images'] for s in stats.values())\n",
    "    total_labels = sum(s['labels'] for s in stats.values())\n",
    "    print(f\"{'TOTAL':8s} - Images: {total_images:5d}, Labels: {total_labels:5d}\")\n",
    " \n",
    "    for split, counts in stats.items():\n",
    "        if counts['images'] != counts['labels'] and counts['images'] > 0:\n",
    "            print(f\"\\n Warning: Mismatch in {split} split - {counts['images']} images but {counts['labels']} labels\")\n",
    "else:\n",
    "    print(\" Skipping - dataset not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b82dda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_exists:\n",
    "    distribution = analyze_dataset_distribution(DATA_DIR)\n",
    "\n",
    "    for split, stats in distribution.items():\n",
    "        if stats['total_images'] > 0:\n",
    "            print(f\"\\n{split.upper()}:\")\n",
    "            print(f\"  Total Images: {stats['total_images']}\")\n",
    "            print(f\"  Total Objects: {stats['total_objects']}\")\n",
    "            print(f\"  Avg Objects/Image: {stats['avg_objects_per_image']:.2f}\")\n",
    "            print(f\"  Avg Object Size: {stats['avg_object_size']:.4f} (normalized)\")\n",
    "            print(f\"  Min Object Size: {stats['min_object_size']:.4f}\")\n",
    "            print(f\"  Max Object Size: {stats['max_object_size']:.4f}\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping - dataset not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47275ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if data_exists and (DATA_DIR / 'images' / 'train').exists():\n",
    "    train_images = list((DATA_DIR / 'images' / 'train').glob('*.jpg')) + \\\n",
    "                   list((DATA_DIR / 'images' / 'train').glob('*.png'))\n",
    "    \n",
    "    if len(train_images) > 0:\n",
    "        num_samples = min(6, len(train_images))\n",
    "        sample_images = np.random.choice(train_images, num_samples, replace=False)\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for idx, img_path in enumerate(sample_images):\n",
    "            label_path = DATA_DIR / 'labels' / 'train' / (img_path.stem + '.txt')\n",
    "            \n",
    "            # Visualize\n",
    "            img = visualize_annotations(img_path, label_path, data_config['names'])\n",
    "            \n",
    "            axes[idx].imshow(img)\n",
    "            axes[idx].set_title(f'{img_path.name}', fontsize=10)\n",
    "            axes[idx].axis('off')\n",
    "        \n",
    "        plt.suptitle('Sample Training Images with Annotations', fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(RESULTS_DIR / 'sample_annotations.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nVisualized {num_samples} sample images\")\n",
    "        print(f\"   Saved to: {RESULTS_DIR / 'sample_annotations.png'}\")\n",
    "    else:\n",
    "        print(\"No images found in training directory\")\n",
    "else:\n",
    "    print(\" Skipping - dataset not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61708b2d",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d392aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize YOLO model\n",
    "model_name = model_config['model_name']\n",
    "print(f\"Initializing {model_name} model...\")\n",
    "\n",
    "# Load pre-trained model\n",
    "model = YOLO(model_name)\n",
    "\n",
    "print(f\"Model initialized: {model_name}\")\n",
    "print(f\"\\nModel Summary:\")\n",
    "print(model.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fc8766",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_config_path = CONFIGS_DIR / 'data_config.yaml'\n",
    "training_data_config = data_config.copy()\n",
    "training_data_config['path'] = str(DATA_DIR.absolute())\n",
    "\n",
    "training_config_path = CONFIGS_DIR / 'training_data_config.yaml'\n",
    "with open(training_config_path, 'w') as f:\n",
    "    yaml.dump(training_data_config, f, default_flow_style=False)\n",
    "\n",
    "print(f\"Training configuration prepared\")\n",
    "print(f\"   Config path: {training_config_path}\")\n",
    "print(f\"   Dataset path: {training_data_config['path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0777b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "results = model.train(\n",
    "    data=str(training_config_path),\n",
    "    epochs=40,\n",
    "    imgsz=model_config['imgsz'],\n",
    "    batch=model_config['batch'],\n",
    "    optimizer=model_config['optimizer'],\n",
    "    lr0=model_config['lr0'],\n",
    "    lrf=model_config['lrf'],\n",
    "    momentum=model_config['momentum'],\n",
    "    weight_decay=model_config['weight_decay'],\n",
    "    \n",
    "    hsv_h=model_config['hsv_h'],\n",
    "    hsv_s=model_config['hsv_s'],\n",
    "    hsv_v=model_config['hsv_v'],\n",
    "    degrees=model_config['degrees'],\n",
    "    translate=model_config['translate'],\n",
    "    scale=model_config['scale'],\n",
    "    shear=model_config['shear'],\n",
    "    perspective=model_config['perspective'],\n",
    "    flipud=model_config['flipud'],\n",
    "    fliplr=model_config['fliplr'],\n",
    "    mosaic=model_config['mosaic'],\n",
    "    mixup=model_config['mixup'],\n",
    "    \n",
    "    box=model_config['box'],\n",
    "    cls=model_config['cls'],\n",
    "    dfl=model_config['dfl'],\n",
    "    patience=10,\n",
    "    save=model_config['save'],\n",
    "    save_period=model_config['save_period'],\n",
    "    plots=model_config['plots'],\n",
    "    device=model_config['device'],\n",
    "    amp=model_config['amp'],\n",
    "    \n",
    "    # Project paths\n",
    "    project=str(TRAINED_DIR),\n",
    "    name='aerial_person_detection',\n",
    "    exist_ok=True,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"raining Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f927407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_path = TRAINED_DIR / 'aerial_person_detection_conminedV2'\n",
    "best_model_path = results_path / 'weights' / 'best.pt'\n",
    "last_model_path = results_path / 'weights' / 'last.pt'\n",
    "\n",
    "print(\" Training Results:\")\n",
    "print(f\"\\n   Results directory: {results_path}\")\n",
    "print(f\"   Best model: {best_model_path}\")\n",
    "print(f\"   Last model: {last_model_path}\")\n",
    "\n",
    "if best_model_path.exists():\n",
    "    print(f\"\\n  Best model saved successfully\")\n",
    "    print(f\"     Size: {best_model_path.stat().st_size / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b82df6",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e840820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best trained model\n",
    "if best_model_path.exists():\n",
    "    trained_model = YOLO(str(best_model_path))\n",
    "    print(f\" Loaded best model from: {best_model_path}\")\n",
    "else:\n",
    "    print(\"Best model not found. Please train the model first.\")\n",
    "    trained_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d216320",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if trained_model is not None:\n",
    "    print(\"\\nValidating model on validation set...\\n\")\n",
    "    \n",
    "    val_results = trained_model.val(\n",
    "        data=str(training_config_path),\n",
    "        imgsz=model_config['imgsz'],\n",
    "        batch=model_config['batch'],\n",
    "        conf=model_config['conf'],\n",
    "        iou=model_config['iou'],\n",
    "        device=model_config['device'],\n",
    "        plots=True,\n",
    "        save_json=True,\n",
    "    )\n",
    "    \n",
    "\n",
    "    print(f\"\\n   mAP@0.5: {val_results.box.map50:.4f}\")\n",
    "    print(f\"   mAP@0.5:0.95: {val_results.box.map:.4f}\")\n",
    "    print(f\"   Precision: {val_results.box.mp:.4f}\")\n",
    "    print(f\"   Recall: {val_results.box.mr:.4f}\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping validation - model not loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2ddd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if results_path.exists():\n",
    "    print(\"Generating training plots...\\n\")\n",
    "    \n",
    "    try:\n",
    "        plot_training_results(results_path)\n",
    "        print(\"Training plots generated\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not generate custom plots: {e}\")\n",
    "        print(\"   Check the results directory for YOLO's built-in plots\")\n",
    "else:\n",
    "    print(\"Results not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ddb121",
   "metadata": {},
   "outputs": [],
   "source": [
    "if results_path.exists():\n",
    "    plot_files = [\n",
    "        'results.png',\n",
    "        'confusion_matrix.png',\n",
    "        'F1_curve.png',\n",
    "        'PR_curve.png',\n",
    "        'P_curve.png',\n",
    "        'R_curve.png'\n",
    "    ]\n",
    "    \n",
    "    available_plots = []\n",
    "    for plot_file in plot_files:\n",
    "        plot_path = results_path / plot_file\n",
    "        if plot_path.exists():\n",
    "            available_plots.append(plot_path)\n",
    "    \n",
    "    if available_plots:\n",
    "        print(f\"\\nDisplaying {len(available_plots)} training plots:\\n\")\n",
    "\n",
    "        n_plots = len(available_plots)\n",
    "        n_cols = 2\n",
    "        n_rows = (n_plots + 1) // 2\n",
    "        \n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 6*n_rows))\n",
    "        if n_plots == 1:\n",
    "            axes = [axes]\n",
    "        else:\n",
    "            axes = axes.flatten()\n",
    "        \n",
    "        for idx, plot_path in enumerate(available_plots):\n",
    "            img = Image.open(plot_path)\n",
    "            axes[idx].imshow(img)\n",
    "            axes[idx].set_title(plot_path.stem.replace('_', ' ').title(), fontsize=12, fontweight='bold')\n",
    "            axes[idx].axis('off')\n",
    "        \n",
    "        for idx in range(len(available_plots), len(axes)):\n",
    "            axes[idx].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(METRICS_DIR / 'all_training_plots.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No plots found in results directory\")\n",
    "else:\n",
    "    print(\"Results directory not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19338fc",
   "metadata": {},
   "source": [
    "## 5. Inference and Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeb7745",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if trained_model is not None:\n",
    "    test_images_dir = DATA_DIR / 'images' / 'test'\n",
    "    \n",
    "    if test_images_dir.exists():\n",
    "        test_images = list(test_images_dir.glob('*.jpg')) + list(test_images_dir.glob('*.png'))\n",
    "        \n",
    "        if len(test_images) > 0:\n",
    "            print(f\"ðŸ” Running inference on {len(test_images)} test images...\\n\")\n",
    "            \n",
    "            # Run prediction\n",
    "            results = trained_model.predict(\n",
    "                source=str(test_images_dir),\n",
    "                imgsz=inference_config['imgsz'],\n",
    "                conf=inference_config['conf'],\n",
    "                iou=inference_config['iou'],\n",
    "                max_det=inference_config['max_det'],\n",
    "                device=inference_config['device'],\n",
    "                save=inference_config['save_img'],\n",
    "                save_txt=inference_config['save_txt'],\n",
    "                save_conf=inference_config['save_conf'],\n",
    "                show_labels=inference_config['show_labels'],\n",
    "                show_conf=inference_config['show_conf'],\n",
    "                show_boxes=inference_config['show_boxes'],\n",
    "                line_width=inference_config['line_width'],\n",
    "                project=str(PREDICTIONS_DIR),\n",
    "                name='test_predictions',\n",
    "                exist_ok=True,\n",
    "            )\n",
    "            \n",
    "            print(f\"\\n Inference complete!\")\n",
    "            print(f\"   Results saved to: {PREDICTIONS_DIR / 'test_predictions'}\")\n",
    "        else:\n",
    "            print(\" No test images found\")\n",
    "    else:\n",
    "        print(\" Test images directory not found\")\n",
    "        print(f\"   Expected at: {test_images_dir}\")\n",
    "else:\n",
    "    print(\"  Model not loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0071a00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_output = PREDICTIONS_DIR / 'test_predictions'\n",
    "\n",
    "if predictions_output.exists():\n",
    "    predicted_images = list(predictions_output.glob('*.jpg')) + list(predictions_output.glob('*.png'))\n",
    "    \n",
    "    if len(predicted_images) > 0:\n",
    "        num_samples = min(6, len(predicted_images))\n",
    "        sample_predictions = np.random.choice(predicted_images, num_samples, replace=False)\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for idx, pred_path in enumerate(sample_predictions):\n",
    "            img = Image.open(pred_path)\n",
    "            axes[idx].imshow(img)\n",
    "            axes[idx].set_title(f'{pred_path.name}', fontsize=10)\n",
    "            axes[idx].axis('off')\n",
    "        \n",
    "        plt.suptitle('Sample Predictions on Test Set', fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(RESULTS_DIR / 'sample_predictions.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nVisualized {num_samples} sample predictions\")\n",
    "        print(f\"   Saved to: {RESULTS_DIR / 'sample_predictions.png'}\")\n",
    "    else:\n",
    "        print(\" No prediction images found\")\n",
    "else:\n",
    "    print(\"  Predictions directory not found\")\n",
    "    print(\"   Run inference first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b3e7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if trained_model is not None and test_images_dir.exists():\n",
    "    test_images = list(test_images_dir.glob('*.jpg')) + list(test_images_dir.glob('*.png'))\n",
    "    \n",
    "    if len(test_images) > 0:\n",
    "        sample_image = np.random.choice(test_images)\n",
    "        \n",
    "        print(f\" Running inference on: {sample_image.name}\\n\")\n",
    "        results = trained_model.predict(\n",
    "            source=str(sample_image),\n",
    "            imgsz=inference_config['imgsz'],\n",
    "            conf=inference_config['conf'],\n",
    "            save=False,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        result = results[0]\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "        original_img = cv2.imread(str(sample_image))\n",
    "        original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
    "        ax1.imshow(original_img)\n",
    "        ax1.set_title('Original Image', fontsize=14, fontweight='bold')\n",
    "        ax1.axis('off')\n",
    "\n",
    "        pred_img = result.plot()\n",
    "        pred_img = cv2.cvtColor(pred_img, cv2.COLOR_BGR2RGB)\n",
    "        ax2.imshow(pred_img)\n",
    "        \n",
    "        num_detections = len(result.boxes)\n",
    "        ax2.set_title(f'Prediction ({num_detections} persons detected)', fontsize=14, fontweight='bold')\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(RESULTS_DIR / 'single_prediction_demo.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nDetection Details:\")\n",
    "        print(f\"   Number of detections: {num_detections}\")\n",
    "        \n",
    "        if num_detections > 0:\n",
    "            print(f\"\\n   Confidence scores:\")\n",
    "            for idx, box in enumerate(result.boxes):\n",
    "                conf = float(box.conf[0])\n",
    "                print(f\"     Detection {idx+1}: {conf:.3f}\")\n",
    "    else:\n",
    "        print(\"  No test images found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a486fe2a",
   "metadata": {},
   "source": [
    "## 6. Export and Deployment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c2adc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if trained_model is not None:\n",
    "    print(\" Exporting model to different formats...\\n\")\n",
    "    \n",
    "    export_formats = [\n",
    "        ('onnx', 'ONNX (Open Neural Network Exchange)'),\n",
    "        ('torchscript', 'TorchScript'),\n",
    "    ]\n",
    "    \n",
    "    exported_models = {}\n",
    "    \n",
    "    for format_name, description in export_formats:\n",
    "        try:\n",
    "            print(f\"Exporting to {description}...\")\n",
    "            export_path = trained_model.export(format=format_name, imgsz=inference_config['imgsz'])\n",
    "            exported_models[format_name] = export_path\n",
    "            print(f\"  Exported to: {export_path}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"   Export to {format_name} failed: {e}\\n\")\n",
    "    \n",
    "    if exported_models:\n",
    "        for format_name, path in exported_models.items():\n",
    "            print(f\"  {format_name.upper()}: {path}\")\n",
    "else:\n",
    "    print(\"  Model not loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051c01d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if trained_model is not None and best_model_path.exists():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Model Summary\")\n",
    "    print(f\"\\n  Model Architecture: {model_name}\")\n",
    "    print(f\"  Best Model Path: {best_model_path}\")\n",
    "    print(f\"  Model Size: {best_model_path.stat().st_size / (1024*1024):.2f} MB\")\n",
    "    print(f\"\\n  Training Configuration:\")\n",
    "    print(f\"    - Epochs: {model_config['epochs']}\")\n",
    "    print(f\"    - Batch Size: {model_config['batch']}\")\n",
    "    print(f\"    - Image Size: {model_config['imgsz']}\")\n",
    "    print(f\"    - Optimizer: {model_config['optimizer']}\")\n",
    "    print(f\"\\n  Inference Configuration:\")\n",
    "    print(f\"    - Confidence Threshold: {inference_config['conf']}\")\n",
    "    print(f\"    - IoU Threshold: {inference_config['iou']}\")\n",
    "    print(f\"    - Max Detections: {inference_config['max_det']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712d11fc",
   "metadata": {},
   "source": [
    "## 7. Inference on Custom Images/Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95039752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_custom_inference(source_path, save_dir=None, show_result=True):\n",
    "\n",
    "    if trained_model is None:\n",
    "        print(\"Model not loaded. Please train or load a model first.\")\n",
    "        return\n",
    "    \n",
    "    if save_dir is None:\n",
    "        save_dir = PREDICTIONS_DIR / 'custom'\n",
    "    \n",
    "    source_path = Path(source_path)\n",
    "    \n",
    "    if not source_path.exists():\n",
    "        print(f\" Source not found: {source_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\" Running inference on: {source_path.name}\\n\")\n",
    "    \n",
    "    results = trained_model.predict(\n",
    "        source=str(source_path),\n",
    "        imgsz=inference_config['imgsz'],\n",
    "        conf=inference_config['conf'],\n",
    "        iou=inference_config['iou'],\n",
    "        max_det=inference_config['max_det'],\n",
    "        device=inference_config['device'],\n",
    "        save=True,\n",
    "        project=str(save_dir.parent),\n",
    "        name=save_dir.name,\n",
    "        exist_ok=True,\n",
    "    )\n",
    "    \n",
    "    print(f\" Inference complete!\")\n",
    "    print(f\"   Results saved to: {save_dir}\")\n",
    "    \n",
    "    if show_result and source_path.suffix.lower() in ['.jpg', '.jpeg', '.png']:\n",
    "        result = results[0]\n",
    "        num_detections = len(result.boxes)\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        pred_img = result.plot()\n",
    "        pred_img = cv2.cvtColor(pred_img, cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(pred_img)\n",
    "        plt.title(f'Detection Result - {num_detections} persons detected', fontsize=14, fontweight='bold')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\n   Detections: {num_detections}\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9a6147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example: Uncomment and modify to run inference on your custom image\n",
    "# custom_image_path = '/home/abdallah/Downloads/gettyimages-1151323185-612x612.jpg'\n",
    "# results = run_custom_inference(custom_image_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
